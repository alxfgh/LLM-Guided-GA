{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in c:\\users\\alexg\\coding projects\\llm-guided-ga\\.venv\\lib\\site-packages (0.3.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\alexg\\coding projects\\llm-guided-ga\\.venv\\lib\\site-packages (from tiktoken) (2023.3.23)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\alexg\\coding projects\\llm-guided-ga\\.venv\\lib\\site-packages (from tiktoken) (2.29.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\alexg\\coding projects\\llm-guided-ga\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\alexg\\coding projects\\llm-guided-ga\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\alexg\\coding projects\\llm-guided-ga\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\alexg\\coding projects\\llm-guided-ga\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2022.12.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade tiktoken\n",
    "import tiktoken\n",
    "import csv\n",
    "from tiktoken import Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl100k_base = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "enc = tiktoken.Encoding(\n",
    "    name=\"SELFIES_encoder\",\n",
    "    pat_str=cl100k_base._pat_str,\n",
    "    mergeable_ranks=cl100k_base._mergeable_ranks,\n",
    "    special_tokens={\n",
    "        **cl100k_base._special_tokens,\n",
    "        \"[\": 100264,\n",
    "        \"]\": 100265,\n",
    "        \"=\": 100266,\n",
    "        \"#\": 100267,\n",
    "        \"-\": 100268,\n",
    "        \"+\": 100269,\n",
    "        \"@\": 100270,\n",
    "        \"H\": 100271\n",
    "    }\n",
    ")\n",
    "\n",
    "specials_allowed = {'[', ']', '=', '#', '-', '+', '@', 'H'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_encodings(example_string: str) -> None:\n",
    "    \"\"\"Prints a comparison of three string encodings.\"\"\"\n",
    "    # print the example string\n",
    "    print(f'\\nExample string: \"{example_string}\"')\n",
    "    # for each encoding, print the # of tokens, the token integers, and the token bytes\n",
    "    for encoding_name in [\"gpt2\", \"p50k_base\", \"cl100k_base\"]:\n",
    "        encoding = tiktoken.get_encoding(encoding_name)\n",
    "        token_integers = encoding.encode(example_string)\n",
    "        num_tokens = len(token_integers)\n",
    "        token_bytes = [encoding.decode_single_token_bytes(token) for token in token_integers]\n",
    "        print()\n",
    "        print(f\"{encoding_name}: {num_tokens} tokens\")\n",
    "        print(f\"token integers: {token_integers}\")\n",
    "        print(f\"token bytes: {token_bytes}\")\n",
    "    token_ints = enc.encode(example_string, allowed_special={\"[\", \"]\", \"=\"})\n",
    "    num_custom = len(token_ints)\n",
    "    custom_bytes = [enc.decode_single_token_bytes(token) for token in token_ints]\n",
    "    print()\n",
    "    print(f\"Custom encoder: {num_custom}\")\n",
    "    print(f\"token integers: {token_ints}\")\n",
    "    print(f\"token bytes: {custom_bytes}\")\n",
    "\n",
    "\n",
    "compare_encodings(\"[C][N][Branch][C][=C][C][=C][C][=C][Ring1][=Branch][pop][C][=C][C][=C][C][=C][Branch][C][=Branch][=O][pop][N][C][C][Branch][O][pop][C][C][O][C][C][Ring1][#Branch][pop][Ring1][=Branch]\")\n",
    "compare_encodings(\"[=C][O][C][=N][C][Branch][C][=Branch][=O][pop][OH0-1][pop][=C][C][Branch][C][Branch][F][pop][F][pop][=C][Branch][Br][pop][Ring1][#C]\")\n",
    "compare_encodings(\"[NH3+1][C][C][O][C][Branch][N][N][=C][C][=Branch][=O][pop][N][C][=Branch][=O][pop][Ring1][#Branch][pop][C][Branch][O][pop][C][Branch][O][pop][Ring1][P]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
